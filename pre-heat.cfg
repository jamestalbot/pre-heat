[files]
# to scan: file to log urls that still need to be scanned for urls
to_scan: to_scan.urls
# scanned: file to log urls (and durations) that have been scanned
#   also used to prevent newly discovered urls from being added to the queue
scanned: scanned.csv
# errors: file to log urls and any error message encountered while scanning the url
errors:  errors.csv

[workers]
# workers: specify number of subprocesses to spin up doing network requests
pool_size: 10

[criteria]
# url roots: specify relatvie url inclusion criteria
#     pre-heat does not scan urls external to the original site/domain.
#     urls are only kept if they begin with one of the roots specified
#     for example, if you have /foo and /bar as roots
#     and you discover links to urls /foob and /barf, both will be added to scan
#     but if you discover links to urls /afoo and /bbar, neither will be added to scan
#     a url root of / will cause all urls linked from the site to the site to be scanned
url_roots:
    /foo
    /bar

[display]
# dislpay each url as it is scanned for links? (default: True)
urls: True
# display scanned, to-scan, and error counts? (defaults: True)
scanned: True
to_scan: True
errors: True
# display counts after every ___ urls (default: 1)
every: 1
# display timing details? (default: False)
timing: True

